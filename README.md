# ğŸ¤– Model Architecture: Transformer Macro Autoencoder

Transformer ê¸°ë°˜ì˜ ì˜¤í† ì¸ì½”ë”(Autoencoder) êµ¬ì¡°
- ì •ìƒ íŒ¨í„´: ëª¨ë¸ì´ ë†’ì€ ì •í™•ë„ë¡œ ë³µì›í•˜ì—¬ ì¬êµ¬ì„± ì˜¤ì°¨ 0ì— ìˆ˜ë ´í•©ë‹ˆë‹¤.
- ì´ìƒ íŒ¨í„´(ë§¤í¬ë¡œ): ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ëª»í•œ íŒ¨í„´ì´ë¯€ë¡œ ë³µì› ëŠ¥ë ¥ì´ ë–¨ì–´ì ¸ ì¬êµ¬ì„± ì˜¤ì°¨ê°€ ë†’ê²Œ ë°œìƒí•©ã„´ë‹¤.

- Feature Embedding : 5ì°¨ì›ì˜ ì…ë ¥ í”¼ì²˜(x, y, dist ë“±)ë¥¼ d_model(64ì°¨ì›)ì˜ ê³ ì°¨ì› ë²¡í„°ë¡œ í™•ì¥í•˜ì—¬ ë³µì¡í•œ ìƒê´€ê´€ê³„ë¥¼ í•™ìŠµí•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.
- Positional Encoding : TransformerëŠ” RNNê³¼ ë‹¬ë¦¬ ìˆœì„œ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ, ì‹œí€€ìŠ¤ ë‚´ ê° ìœ„ì¹˜ ì •ë³´($1^{st}, 2^{nd}, ...$)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°ë¥¼ ë”í•´ì¤ë‹ˆë‹¤.
- Transformer Encoder : Multi-Head Self-Attention ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ë™ì‹œì— í›‘ìœ¼ë©°, ê³¼ê±°ì˜ ì›€ì§ì„ì´ í˜„ì¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ íŒŒì•…í•©ë‹ˆë‹¤.
- Linear Decoder : ì¸ì½”ë”ê°€ ë½‘ì•„ë‚¸ ì¶”ìƒì ì¸ íŠ¹ì§•ë“¤ì„ ë‹¤ì‹œ ì›ë˜ì˜ 5ê°œ í”¼ì²˜ ì°¨ì›ìœ¼ë¡œ ë³µì›í•©ë‹ˆë‹¤.

Detection Logic
- Normal Patterns: The model reconstructs these with high precision, causing the reconstruction error to converge to zero.
- Anomalous Patterns (Macro): Since these are patterns the model has not encountered during training, the reconstruction capability decreases, resulting in a high reconstruction error.

- Feature Embedding: Expands the 5-dimensional input features (e.g., $x, y, dist$) into a high-dimensional vector of $d_{model}$ (64 dimensions) to prepare the model for learning complex correlations.
- Positional Encoding: Since Transformers do not inherently process sequential order like RNNs, this adds vectors that represent the positional information ($1^{st}, 2^{nd}, \dots$) within the sequence.
- Transformer Encoder: Utilizes the Multi-Head Self-Attention mechanism to scan the entire sequence simultaneously, capturing how past movements influence the present state.
- Linear Decoder: Reconstructs the abstract features extracted by the encoder back into the original 5-feature dimensions.

![Architecture Diagram](./public/Architecture.png)

# Update Ver 1.0.1
Feature
- Enhanced Tracking Precision: Added .env persistence for tolerance (lower values allow for finer and more detailed mouse data sampling).
- Improved System Stability: Implemented tolerance to ensure stable inference and training performance even in low-frequency (Low Hz) environments, alongside Protection Mode for restricted windows.
- Improved Stability (Protection Mode): Added a fail-safe protocol to prevent crashes and ensure stable recording in restricted windows like Task Manager.
- Epoch 50 => 300
- Cliping 
- config.jsonìœ¼ë¡œ ì´ˆê¸° ì…‹íŒ…ê°’ ì •ë¦¬

UI & UX
- The UI has been refined for a more sophisticated look.
- Tray Mode Integration: Added a "Minimize to Tray" feature to keep the application running in the background, allowing for a clutter-free workspace.

---

# Update Ver 0.0.0
- CLI Mode Expansion: Inference Mode now officially supports both Windows CMD and Linux Terminal environments.
- Portable Release: Executables are now bundled and provided as ZIP archives via PyInstaller for easy deployment.

![Cmdupdate](./public/Cmdupdate.png)

Start => inference Mode => yes
UI => inference Mode => No

Quit => ctrl + shift + q

---
# ì§€ì› í”„ë¡œê·¸ë¨
- postgres
- json

# í•„ìˆ˜ íŒŒì¼
.env
```
# ê¸°ë¡ê¸°
# postgres => postgres, json => json
Recorder=json

# posgresë¥¼ ì‚¬ìš© ì‹œ ê¸°ì…
DB_HOST=localhost
DB_USER=postgres
DB_PASSWORD=your_password
DB_NAME=your_db_name
DB_PORT=0000

# í•„ìˆ˜ ì…ë ¥
SEQ_LEN=100
STRIDE=50
JsonPath=./
threshold=0.7
d_model=256
num_layers=3
dropout=0.3
batch_size=64
lr=0.0005
```

# ì„¤ì¹˜ ëª©ë¡
```
pynput
torch
psycopg2-binary
SQLAlchemy
pydantic_settings
pyautogui
matplotlib
numpy
pyqtgraph 
PySide6
PyQt6
keyboard
```

ëª…ë ¹ì–´
```
pip install -r requirements.txt
```

# ì£¼ì˜ ì‚¬í•­
í•™ìŠµ ì‹œ ì„¤ì •í•œ
SEQ_LEN, d_model, num_layers, dropout

ê°’ì´ ì¶”ë¡  ì‹œ ë™ì¼ í•´ì•¼ ì •ìƒ ì‘ë™ í•¨.

# ì‚¬ìš© ì„¤ëª…ì„œ (Manual)
Manual.pptx

# ì˜ˆì‹œìš© ëª¨ë¸
model ê²½ë¡œ => app.models.weights
=> SED_LEN=100, d_model=256, num_layers=3, dropout=0.3

# ì˜ìƒ
[![ì‹¤í–‰ ì˜ìƒ](https://img.youtube.com/vi/iwi31PxQc3I/0.jpg)](https://youtu.be/iwi31PxQc3I)
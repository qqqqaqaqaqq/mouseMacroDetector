import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import pandas as pd
import time
import numpy as np
import json

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler

import app.core.globals as g_vars
import joblib
# ëª¨ë¸
from app.models.MousePoint import MousePoint
from app.models.TransformerMacroDetector import TransformerMacroAutoencoder, MacroDataset

import app.repostitories.DBController as DBController
import app.repostitories.JsonController as JsonController

from app.services.indicators import indicators_generation
from multiprocessing import Queue

from app.utilites.make_df_from_points import make_df_from_points
from app.utilites.points_to_features import points_to_features
from app.utilites.save_confing import update_parameters

def train_plot_main(train_queue: Queue):
    import sys
    from app.services.RealTimeMonitor import TrainMonitor 
    from PyQt6.QtCore import QTimer
    
    monitor = TrainMonitor(window_size=1000) # Epoch ìˆ˜ì— ë§ì¶° ì¡°ì ˆ
    
    def update():
        # íì— ìŒ“ì¸ ëª¨ë“  ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ ë”œë ˆì´ ë°©ì§€
        while not train_queue.empty():
            try:
                data = train_queue.get_nowait()
                # data format: (avg_train_loss, avg_val_loss)
                monitor.update_view(data[0], data[1])
            except Exception as e:
                print(f"Update error: {e}")
                break
                
    timer = QTimer()
    timer.timeout.connect(update)
    timer.start(100) # ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ ì£¼ê¸° (ms)
    
    sys.exit(monitor.app.exec())

class TrainMode():
    def __init__(self, stop_event=None, log_queue:Queue=None):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        self.stop_event=stop_event
        self.seq_len=g_vars.SEQ_LEN
        self.log_queue:Queue=log_queue

        self.plot_proc = None


    def start_plot_process(self):
        if self.plot_proc is not None and self.plot_proc.is_alive():
            return

        from multiprocessing import Process
        self.plot_proc = Process(
            target=train_plot_main,
            args=(g_vars.TRAIN_DATA,),
            daemon=False
        )
        self.plot_proc.start()
        
    # train
    def train_start(self, train_dataset, val_dataset, batch_size=g_vars.batch_size, epochs=2000, lr=g_vars.lr,
                    device=None, model=None, stop_event=None, patience=20, log_queue=None, save_path="best_model.pth"):
        try:
            self.start_plot_process()

            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
            val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

            criterion = nn.MSELoss()
            optimizer = optim.Adam(model.parameters(), lr=lr)

            best_val_loss = float('inf')
            epochs_no_improve = 0
            
            # ì¶”ì²œ ì„ê³„ì¹˜ë¥¼ ì €ì¥í•  ë³€ìˆ˜
            recommended_base_threshold = 0.0

            for epoch in range(epochs):
                if stop_event.is_set():
                    self.train_stop_event(log_queue=log_queue)
                    break

                # ===== Train Phase =====
                model.train()
                total_train_loss = 0
                for batch_x in train_loader:
                    batch_x = batch_x.to(device)
                    optimizer.zero_grad()
                    outputs = model(batch_x)
                    loss = criterion(outputs, batch_x)
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
                    total_train_loss += loss.item() * batch_x.size(0)

                avg_train_loss = total_train_loss / len(train_dataset)

                # ===== Validation Phase =====
                model.eval()
                total_val_loss = 0
                all_val_errors = [] # ìƒ˜í”Œë³„ ê°œë³„ ì—ëŸ¬ ìˆ˜ì§‘ìš© ë¦¬ìŠ¤íŠ¸

                with torch.no_grad():
                    for batch_x in val_loader:
                        batch_x = batch_x.to(device)
                        outputs = model(batch_x)
                        
                        # 1. í‰ê·  Loss ê³„ì‚° (ê¸°ì¡´ ìœ ì§€)
                        loss = criterion(outputs, batch_x)
                        total_val_loss += loss.item() * batch_x.size(0)
                        
                        # 2. ìƒ˜í”Œë³„ ê°œë³„ MAE ì—ëŸ¬ ìˆ˜ì§‘ (ì„ê³„ì¹˜ ì˜ˆì¸¡ìš©)
                        # outputs/batch_x: (Batch, Seq_len, Features)
                        # ê° ìƒ˜í”Œë³„ë¡œ ëª¨ë“  ì°¨ì›ì˜ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ë¥¼ êµ¬í•¨
                        sample_errors = torch.abs(outputs - batch_x).mean(dim=(1, 2))
                        all_val_errors.extend(sample_errors.cpu().numpy())

                avg_val_loss = total_val_loss / len(val_dataset)

                # 3. ì„ê³„ì¹˜ í†µê³„ ê³„ì‚° (ìƒìœ„ 99.7% ì§€ì  ì¶”ì¶œ)
                # ì´ ê°’ì€ "ì •ìƒ ë°ì´í„° ì¤‘ ê°€ì¥ íŠ€ëŠ” ë†ˆë“¤"ì˜ ê¸°ì¤€ì„ ì´ ë©ë‹ˆë‹¤.
                current_epoch_threshold = np.percentile(all_val_errors, 99.7)

                # ===== Logging & Early Stopping =====
                status_msg = f"Epoch {epoch+1}/{epochs} | Train: {avg_train_loss:.6f} | Val: {avg_val_loss:.6f} | Est.Thresh: {current_epoch_threshold:.6f}"

                if g_vars.TRAIN_DATA is not None:
                    g_vars.TRAIN_DATA.put((float(avg_train_loss), float(avg_val_loss)))

                if log_queue: log_queue.put(status_msg)

                if avg_val_loss < best_val_loss:
                    best_val_loss = avg_val_loss
                    recommended_base_threshold = current_epoch_threshold # ìµœì  ëª¨ë¸ì¼ ë•Œì˜ ì„ê³„ì¹˜ ê¸°ì–µ
                    epochs_no_improve = 0
                    torch.save(model.state_dict(), save_path)
                    if log_queue: log_queue.put(f"  >> [Model Saved] Best Val Loss: {best_val_loss:.6f}")
                else:
                    epochs_no_improve += 1
                    if epochs_no_improve >= patience:
                        if log_queue: log_queue.put(f"Early Stopping: {patience} epoch ë™ì•ˆ ê°œì„  ì—†ìŒ.")
                        if stop_event: stop_event.set()
                        break

            # ìµœì¢… ì¶œë ¥ ì‹œ ì¶”ì²œ ì„ê³„ê°’ì„ í•¨ê»˜ ì•Œë ¤ì¤Œ
            final_msg = f"í•™ìŠµ ì¢…ë£Œ. ìµœì  Val Loss: {best_val_loss:.6f} | ì¶”ì²œ Base Threshold: {recommended_base_threshold:.6f}"
            if log_queue: log_queue.put(final_msg)
            
            # g_varsì— ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ì €ì¥í•˜ì—¬ _inferì—ì„œ ì“°ê²Œ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
            g_vars.threshold = recommended_base_threshold 
            update_parameters({"THRES" : recommended_base_threshold})

        finally:
            self.train_stop_event(log_queue=log_queue)
            if 'model' in locals():
                model_cpu = model.to('cpu')
                del model_cpu
                del model
            import gc
            gc.collect()
        
    def main(self):
        self.log_queue.put(f"device : {self.device} | SEQ_LEN : {g_vars.SEQ_LEN} | STRIDE : {g_vars.STRIDE}")

        # ===== ë°ì´í„° ì½ê¸° =====
        if g_vars.Recorder == "postgres":
            user_all: list[MousePoint] = DBController.read(True, log_queue=self.log_queue)
            is_dict = False
        elif g_vars.Recorder == "json":
            user_all: list[dict] = JsonController.read(True, log_queue=self.log_queue)
            is_dict = True

        self.log_queue.put(f"user_all length : {len(user_all)}")

        user_df_chunk = make_df_from_points(user_all, is_dict=is_dict)

        # ===== Feature ê³„ì‚° =====
        setting_user_df_chunk: pd.DataFrame = indicators_generation(user_df_chunk)
        
        # ===== Feature í•„í„° =====
        setting_user_df_chunk = setting_user_df_chunk[g_vars.FEATURES].copy()

        clip_bounds_dict = {}
        for col in g_vars.FEATURES:
            # numpy float64ë¥¼ ì¼ë°˜ python floatìœ¼ë¡œ ë³€í™˜í•˜ì—¬ JSON ì—ëŸ¬ ë°©ì§€
            lower = float(setting_user_df_chunk[col].quantile(0.01))
            upper = float(setting_user_df_chunk[col].quantile(0.99))
            clip_bounds_dict[col] = {"min": lower, "max": upper}

            setting_user_df_chunk[col] = setting_user_df_chunk[col].clip(lower, upper)
        
        # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
        g_vars.CLIP_BOUNDS = clip_bounds_dict

        print(f"{json.dumps(clip_bounds_dict, indent=2)} Save")

        print(f"setting_user_df_chunk : {setting_user_df_chunk}")


        if len(setting_user_df_chunk) < g_vars.SEQ_LEN:
            self.log_queue.put("ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        # ===== Train/Val split =====
        user_train_df: pd.DataFrame
        user_val_df: pd.DataFrame

        user_train_df, user_val_df = train_test_split(setting_user_df_chunk, test_size=0.2, shuffle=False)

        # ===== Sequence =====q
        user_train_seq, user_train_pass_seq = points_to_features(df_chunk=user_train_df, seq_len=g_vars.SEQ_LEN, stride=g_vars.STRIDE, log_queue=self.log_queue)

        user_val_seq, user_val_pass_seq = points_to_features(df_chunk=user_val_df, seq_len=g_vars.SEQ_LEN, stride=g_vars.STRIDE, log_queue=self.log_queue)

        self.log_queue.put(f"Length => user_train_seq : {user_train_pass_seq}")
        self.log_queue.put(f"Length => user_val_pass_seq : {user_val_pass_seq}")

        X_train = user_train_seq
        X_val = user_val_seq

        # ìŠ¤ì¼€ì¼ë§ ì ìš©
        n_train, seq_len, n_features = X_train.shape
        n_val = X_val.shape[0]

        scaler = RobustScaler()
        
        # [Train ìŠ¤ì¼€ì¼ë§] 2Dë¡œ í¼ì³ì„œ í•™ìŠµ(fit) í›„ ë³€í™˜(transform)
        X_train_reshaped = X_train.reshape(-1, n_features)
        X_train_scaled = scaler.fit_transform(X_train_reshaped)
        X_train = X_train_scaled.reshape(n_train, seq_len, n_features)

        # [Val ìŠ¤ì¼€ì¼ë§] Train ê¸°ì¤€ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ë³€í™˜ë§Œ ìˆ˜í–‰ (ì¤‘ìš”: fit ì•ˆí•¨)
        X_val_reshaped = X_val.reshape(-1, n_features)
        X_val_scaled = scaler.transform(X_val_reshaped)
        X_val = X_val_scaled.reshape(n_val, seq_len, n_features)
        joblib.dump(scaler, g_vars.scaler_path)
        
        train_dataset = MacroDataset(X_train)
        val_dataset   = MacroDataset(X_val)
        
        print(f"Total samples: {len(train_dataset)}")

        # 2. ì²« ë²ˆì§¸ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
        sample_x = train_dataset[0]

        print("--- First Sample Data ---")
        print(f"Input Shape (seq_len, features): {sample_x.shape}")
        print("--- Raw Input (First 5 steps) ---")
        print(sample_x[:5])

        model = TransformerMacroAutoencoder(
            input_size=len(g_vars.FEATURES),
            d_model=g_vars.d_model,
            nhead=4,
            num_layers=g_vars.num_layers,
            dim_feedforward=128,
            dropout=g_vars.dropout
        ).to(self.device)

        timeinterval = 10

        while timeinterval != 0:
            if self.stop_event.is_set():
                self.train_stop_event(log_queue=self.log_queue)
                return

            timeinterval -= 1
            self.log_queue.put(f"train ì‹œì‘ê¹Œì§€ count : {timeinterval}")

            time.sleep(1)

        self.train_start(
            train_dataset=train_dataset,
            val_dataset=val_dataset, 
            batch_size=g_vars.batch_size, 
            lr=g_vars.lr,
            epochs=300,
            device=self.device, 
            model=model, 
            stop_event=self.stop_event, 
            patience=20, 
            log_queue=self.log_queue, 
            save_path=g_vars.save_path
        )

    def train_stop_event(self, log_queue: Queue = None):
        # 1. ì‹œê°í™” í”„ë¡œì„¸ìŠ¤ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ (ì‚´ë ¤ë‘ )
        if log_queue: 
            log_queue.put("âœ… í•™ìŠµ ë£¨í”„ ì¢…ë£Œ (ê·¸ë˜í”„ëŠ” ìœ ì§€ë©ë‹ˆë‹¤)")

        # 2. GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ì´ê²ƒë§Œ í•´ë„ ë¦¬ì†ŒìŠ¤ í™•ë³´ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤)
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        if log_queue: 
            log_queue.put("ğŸ§¹ GPU Cache Cleared")
import torch
import torch.nn as nn

from torch.utils.data import DataLoader
import pandas as pd
import time
import numpy as np
import json

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer

import app.core.globals as g_vars
import joblib

from app.models.MousePoint import MousePoint
from app.models.TransformerMacroDetector import TransformerMacroAutoencoder, MacroDataset

import app.repostitories.DBController as DBController
import app.repostitories.JsonController as JsonController

from app.core.indicators import indicators_generation
from multiprocessing import Queue

from app.utilites.make_df_from_points import make_df_from_points
from app.utilites.make_sequence import make_seq
from app.utilites.make_gauss import make_gauss
from app.utilites.save_confing import update_parameters
from app.utilites.loss_caculation import Loss_Calculation, inference_score

def train_plot_main(train_queue: Queue):
    import sys
    from app.utilites.train_plot_monitor import TrainMonitor
    from PyQt6.QtCore import QTimer

    monitor = TrainMonitor(window_size=1000)

    def update():
        while not train_queue.empty():
            epoch, train_loss, val_loss = train_queue.get_nowait()
            monitor.update_view(epoch, train_loss, val_loss)

    timer = QTimer()
    timer.timeout.connect(update)
    timer.start(100)

    sys.exit(monitor.app.exec())


class TrainMode():
    def __init__(self, stop_event=None, log_queue:Queue=None):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        self.stop_event=stop_event
        self.seq_len=g_vars.SEQ_LEN
        self.log_queue:Queue=log_queue

        self.plot_proc = None


    def start_plot_process(self):
        if self.plot_proc is not None and self.plot_proc.is_alive():
            return

        from multiprocessing import Process
        self.plot_proc = Process(
            target=train_plot_main,
            args=(g_vars.TRAIN_DATA,),
            daemon=False
        )
        self.plot_proc.start()

    # train
    def train_start(self, train_dataset, val_dataset, batch_size=g_vars.batch_size, epochs=2000, lr=g_vars.lr,
                    device=None, model=None, stop_event=None, patience=20, log_queue:Queue=None, save_path="best_model.pth"):
        try:
            log_queue.put(f"ğŸš€ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ | LR: {lr}, Loss: MSE")
            self.start_plot_process()

            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
            val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

            criterion = criterion = nn.HuberLoss(delta=3.0)
            optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=g_vars.weight_decay)
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-5
            )

            best_val_loss = float('inf')
            epochs_no_improve = 0
            standard_val_loss = None 
            recommended_base_threshold = 0.0

            for epoch in range(epochs):
                if stop_event.is_set():
                    self.train_stop_event(log_queue=log_queue)
                    break

                # ===== Train Phase =====
                model.train()
                total_train_loss = 0
                for batch_x in train_loader:
                    batch_x = batch_x.to(device)
                    optimizer.zero_grad()
                    outputs = model(batch_x)
                    loss = criterion(outputs, batch_x)
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
                    total_train_loss += loss.item() * batch_x.size(0)

                avg_train_loss = total_train_loss / len(train_dataset)

                # ===== Validation Phase =====
                model.eval()
                total_val_loss = 0
                all_val_errors = [] 

                with torch.no_grad():
                    for batch_x in val_loader:
                        batch_x = batch_x.to(device)
                        outputs = model(batch_x)
                        
                        # Loss_Calculation ìŠ¤ìœ„ì¹­ í•¨ìˆ˜ ì‚¬ìš©
                        sample_errors = inference_score(outputs=outputs, batch=batch_x, device=device)
                        all_val_errors.extend(sample_errors.cpu().numpy())
                        
                        loss = criterion(outputs, batch_x)
                        total_val_loss += loss.item() * batch_x.size(0)

                avg_val_loss = total_val_loss / len(val_dataset)
                
                # ì°¨íŠ¸ ë°ì´í„° ì „ì†¡ (ì´ ë¶€ë¶„ì´ ìˆì–´ì•¼ ì‹¤ì‹œê°„ ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§‘ë‹ˆë‹¤)
                if g_vars.TRAIN_DATA:
                    g_vars.TRAIN_DATA.put((epoch + 1, float(avg_train_loss), float(avg_val_loss)))
                
                # ê°œì„ ìœ¨ ê¸°ì¤€ì  ì§€ì—° ì„¤ì • (Epoch 3)
                if standard_val_loss is None and epoch >= 2: 
                    standard_val_loss = avg_val_loss
                    log_queue.put(f"ğŸ“ ê¸°ì¤€ì  ì„¤ì •(E{epoch+1}): {standard_val_loss:.6f}")
                
                scheduler.step(avg_val_loss)

                # Threshold ê³„ì‚°
                errors = np.array(all_val_errors)
                current_epoch_threshold = np.percentile(errors, 95.0)

                # ë¡œê·¸ ì¶œë ¥
                status_msg = f"Epoch {epoch+1} | Train: {avg_train_loss:.6f} | Val: {avg_val_loss:.6f} | Thres: {current_epoch_threshold:.6f}"
                if log_queue: log_queue.put(status_msg)

                # ê°œì„ ìœ¨ ì²´í¬ ë° ì¡°ê¸° ì¢…ë£Œ
                if standard_val_loss is not None:
                    improvement_total = (standard_val_loss - avg_val_loss) / standard_val_loss
                    if log_queue: log_queue.put(f"ğŸ“Š ê°œì„ ìœ¨: {improvement_total * 100:.2f}% / ëª©í‘œ: {g_vars.improvement_val_loss_cut * 100}%")
                    
                    if improvement_total >= g_vars.improvement_val_loss_cut:
                        recommended_base_threshold = current_epoch_threshold
                        best_val_loss = avg_val_loss
                        torch.save(model.state_dict(), save_path)
                        if log_queue: log_queue.put(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±! ({improvement_total*100:.1f}%) í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        break

                # Best ëª¨ë¸ ì €ì¥ ë¡œì§
                if avg_val_loss < best_val_loss:
                    best_val_loss = avg_val_loss
                    recommended_base_threshold = current_epoch_threshold
                    torch.save(model.state_dict(), save_path)
                    epochs_no_improve = 0
                    if log_queue: log_queue.put(f" >> [Best Saved] Loss: {best_val_loss:.6f}")
                else:
                    epochs_no_improve += 1
                    if log_queue: log_queue.put(f" >> [No Improve] {epochs_no_improve}/{patience}")
                    if epochs_no_improve >= patience:
                        if log_queue: log_queue.put(f"Early Stopping ë°œìƒ!")
                        break

            # ìµœì¢… íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
            g_vars.threshold = recommended_base_threshold 
            update_parameters({"THRES" : recommended_base_threshold})
            
            with g_vars.lock:
                g_vars.GLOBAL_CHANGE = True

        finally:
            self.train_stop_event(log_queue=log_queue)
            import gc
            gc.collect()
            torch.cuda.empty_cache()

    def main(self):
        self.log_queue.put(f"device : {self.device} | SEQ_LEN : {g_vars.SEQ_LEN} | STRIDE : {g_vars.STRIDE}")

        # ===== ë°ì´í„° ì½ê¸° =====
        if g_vars.Recorder == "postgres":
            user_all: list[MousePoint] = DBController.read(True, log_queue=self.log_queue)
            is_dict = False
        elif g_vars.Recorder == "json":
            user_all: list[dict] = JsonController.read(True, log_queue=self.log_queue)
            is_dict = True
            
        user_df_chunk = make_df_from_points(user_all, is_dict=is_dict)

        user_df_chunk= user_df_chunk.sort_values('timestamp').reset_index(drop=True)

        # ===== ì§€í‘œ ìƒì„± ======
        setting_user_df_chunk: pd.DataFrame = indicators_generation(user_df_chunk)
        setting_user_df_chunk = setting_user_df_chunk[g_vars.FEATURES].copy()
        print("âœ… ì§€í‘œ ìƒì„± ì„±ê³µ")

        # ==== ìŠ¤ì¼€ì¼ ì‘ì—… =====
        scaler = RobustScaler()

        scaled_array = scaler.fit_transform(setting_user_df_chunk[g_vars.FEATURES])
        chunks_scaled_df = pd.DataFrame(scaled_array, columns=g_vars.FEATURES)
        joblib.dump(scaler, g_vars.scaler_path)

        chunks_scaled = chunks_scaled_df.values

        final_input:np.array = make_seq(data=chunks_scaled, seq_len=g_vars.SEQ_LEN, stride=g_vars.STRIDE)
        
        print(f"âœ… Cliping Save")

        print(f"âœ… ìµœì¢… ì‹œí€€ìŠ¤ Shape: {final_input.shape}")
        print(f"ğŸš€ ì²« ë²ˆì§¸ ì‹œí€€ìŠ¤ì˜ ì²« ë©ì–´ë¦¬ ì˜ˆì‹œ:\n{final_input[0][0]}")
    
        stats = chunks_scaled_df.agg(['mean', 'std']).T
        print(f"ğŸ“Š ìŠ¤ì¼€ì¼ë§ í›„ í‰ê·  & í‘œì¤€ í¸ì°¨ {stats}")

        print(f"ğŸ“Š ìŠ¤ì¼€ì¼ë§ í›„ ìµœì†Œê°’: {final_input.min(axis=(0,1))}")
        print(f"ğŸ“Š ìŠ¤ì¼€ì¼ë§ í›„ ìµœëŒ€ê°’: {final_input.max(axis=(0,1))}")

        # ==== ë°ì´í„° ì…‹ ì •ì˜ ====
        train, val = train_test_split(final_input, test_size=0.2, shuffle=True)

        train_dataset = MacroDataset(train)
        val_dataset   = MacroDataset(val)

        # ==== ëª¨ë¸ ì •ì˜ ====
        model = TransformerMacroAutoencoder(
            input_size=len(g_vars.FEATURES),
            d_model=g_vars.d_model,
            nhead=g_vars.n_head,
            num_layers=g_vars.num_layers,
            dim_feedforward=g_vars.dim_feedforward,
            dropout=g_vars.dropout
        ).to(self.device)

        # ==== ì‹œì‘ íƒ€ì´ë¨¸ ====
        timeinterval = 5

        while timeinterval != 0:
            if self.stop_event.is_set():
                self.train_stop_event(log_queue=self.log_queue)
                return

            timeinterval -= 1
            self.log_queue.put(f"train ì‹œì‘ê¹Œì§€ count : {timeinterval}")

            time.sleep(1)

        # ==== íŠ¸ë ˆì¸ ì •ì˜ ====
        self.train_start(
            train_dataset=train_dataset,
            val_dataset=val_dataset, 
            batch_size=g_vars.batch_size, 
            lr=g_vars.lr,
            epochs=g_vars.epoch,
            device=self.device, 
            model=model, 
            stop_event=self.stop_event, 
            patience=g_vars.patience, 
            log_queue=self.log_queue, 
            save_path=g_vars.save_path
        )

    def train_stop_event(self, log_queue: Queue = None):
        # 1. ì‹œê°í™” í”„ë¡œì„¸ìŠ¤ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ (ì‚´ë ¤ë‘ )
        if log_queue: 
            log_queue.put("âœ… í•™ìŠµ ë£¨í”„ ì¢…ë£Œ (ê·¸ë˜í”„ëŠ” ìœ ì§€ë©ë‹ˆë‹¤)")

        # 2. GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ì´ê²ƒë§Œ í•´ë„ ë¦¬ì†ŒìŠ¤ í™•ë³´ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤)
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        if log_queue: 
            log_queue.put("ğŸ§¹ GPU Cache Cleared")

        with g_vars.lock:
            g_vars.GLOBAL_CHANGE = True